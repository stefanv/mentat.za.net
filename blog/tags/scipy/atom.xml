<?xml version="1.0" encoding="utf-8"?> 
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en-us">
    <generator uri="https://gohugo.io/" version="0.80.0">Hugo</generator><title type="html"><![CDATA[scipy on Stéfan's blog]]></title>
    
    
    
            <link href="https://mentat.za.net/blog/tags/scipy/" rel="alternate" type="text/html" title="HTML" />
            <link href="https://mentat.za.net/blog/tags/scipy/atom.xml" rel="self" type="application/atom" title="atom" />
    <updated>2021-01-14T01:49:31-08:00</updated>
    
    
    <author>
            <name>Stéfan van der Walt</name>
            </author>
    
        <id>https://mentat.za.net/blog/tags/scipy/</id>
    
        
        <entry>
            <title type="html"><![CDATA[Scientific Python at Microscopy & MicroAnalysis 2019]]></title>
            <link href="https://mentat.za.net/blog/2019/08/06/portland-microscopy/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://mentat.za.net/blog/2012/09/30/scikits-image-0-dot-7/?utm_source=atom_feed" rel="related" type="text/html" title="scikits-image 0.7" />
                <link href="https://mentat.za.net/blog/2013/06/27/scipy2013-proceedings/?utm_source=atom_feed" rel="related" type="text/html" title="SciPy2013 Proceedings" />
                <link href="https://mentat.za.net/blog/2012/09/25/emacs-package-management/?utm_source=atom_feed" rel="related" type="text/html" title="Emacs package management" />
                <link href="https://mentat.za.net/blog/2018/10/31/using-org-mode-with-neomutt/?utm_source=atom_feed" rel="related" type="text/html" title="Linking to emails in org-mode (using neomutt)" />
                <link href="https://mentat.za.net/blog/2016/10/20/websockets-in-python/?utm_source=atom_feed" rel="related" type="text/html" title="WebSockets in Python (and some Redux)" />
            
                <id>https://mentat.za.net/blog/2019/08/06/portland-microscopy/</id>
            
            
            <published>2019-08-06T00:00:00+00:00</published>
            <updated>0001-01-01T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Where we demonstrate a new way of doing interactive image analysis.</blockquote><p>Today, I presented a talk titled <a href="https://doi.org/10.1017/S1431927619001399">&ldquo;Scientific Python: A Mature Computational Ecosystem for Microscopy&rdquo;</a> [<a href="http://www.jhmartins.com/mm2019c/7337/0132.pdf">PDF</a>] at the Microscopy and MicroAnalysis conference in Portland.</p>
<p>A few members of the audience familiar with scientific Python told me they had learned something, so I&rsquo;ll highlight the few topics that I think may have qualified.</p>
<h2 id="scipy-10-paper">SciPy 1.0 paper</h2>
<p>The first official release of SciPy was in 2001, and a mere 16 years later we reached 1.0. This says a lot about the developer community, and how careful they are to label their own work as &ldquo;mature&rdquo;!  To celebrate this project milestone, we <a href="https://arxiv.org/abs/1907.10121">published a preprint on arXiv</a> that outlines the project history and its current status.  It mentions, among other achievements, that SciPy was instrumental in the first <a href="https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.119.161101">gravitational wave detection</a>, as well as the recent <a href="https://iopscience.iop.org/journal/2041-8205/page/Focus_on_EHT">imaging of the black hole in Messier 87</a>.</p>
<h2 id="numpy-__array_function__-protocol">NumPy <code>__array_function__</code> protocol</h2>
<p>The 1.17 release of NumPy (2019-07-26) has support for a <a href="https://numpy.org/neps/nep-0018-array-function-protocol.html">new array function protocol</a>, that allows external libraries to pass their array-like objects through NumPy without them being horribly mangled.  E.g., you may call NumPy&rsquo;s <code>sum</code> on a CuPy array: the computation will happen on the GPU, and the resulting array will still be a CuPy array.</p>
<p>Here is an example:</p>
<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">In [<span style="color:#40a070">24</span>]: <span style="color:#007020;font-weight:bold">import</span> <span style="color:#0e84b5;font-weight:bold">cupy</span> <span style="color:#007020;font-weight:bold">as</span> <span style="color:#0e84b5;font-weight:bold">cp</span>

In [<span style="color:#40a070">25</span>]: x <span style="color:#666">=</span> cp<span style="color:#666">.</span>random<span style="color:#666">.</span>random([<span style="color:#40a070">10</span>, <span style="color:#40a070">10</span>])

In [<span style="color:#40a070">26</span>]: y <span style="color:#666">=</span> x<span style="color:#666">.</span>sum(axis<span style="color:#666">=</span><span style="color:#40a070">0</span>)

In [<span style="color:#40a070">27</span>]: <span style="color:#007020">type</span>(y), y<span style="color:#666">.</span>shape
Out[<span style="color:#40a070">27</span>]: (cupy<span style="color:#666">.</span>core<span style="color:#666">.</span>core<span style="color:#666">.</span>ndarray, (<span style="color:#40a070">10</span>,))

In [<span style="color:#40a070">28</span>]: <span style="color:#007020;font-weight:bold">import</span> <span style="color:#0e84b5;font-weight:bold">numpy</span> <span style="color:#007020;font-weight:bold">as</span> <span style="color:#0e84b5;font-weight:bold">np</span>

In [<span style="color:#40a070">29</span>]: z <span style="color:#666">=</span> np<span style="color:#666">.</span>sum(x, axis<span style="color:#666">=</span><span style="color:#40a070">0</span>)

In [<span style="color:#40a070">30</span>]: <span style="color:#007020">type</span>(z), z<span style="color:#666">.</span>shape
Out[<span style="color:#40a070">30</span>]: (cupy<span style="color:#666">.</span>core<span style="color:#666">.</span>core<span style="color:#666">.</span>ndarray, (<span style="color:#40a070">10</span>,))
</code></pre></div><p>Note how the result is the same, whether you use CuPy or NumPy&rsquo;s <code>sum</code>.</p>
<p>Whereas NumPy used to be the reference implementation for array computation in Python, it is fast evolving into a standard API, implemented by multiple libraries.</p>
<h2 id="pytorch-and-tensorflow-easily-consume-python-images">PyTorch and TensorFlow easily consume Python images</h2>
<p>Images in scientific Python (<code>scikit-image</code>, <code>opencv</code>, etc.) are represented as NumPy arrays.  It is trivial to pass these arrays into deep learning libraries such as TensorFlow:</p>
<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">
<span style="color:#007020;font-weight:bold">from</span> <span style="color:#0e84b5;font-weight:bold">tensorflow.keras.applications.inception_v3</span> <span style="color:#007020;font-weight:bold">import</span> (
    InceptionV3, preprocess_input, decode_predictions
)
<span style="color:#007020;font-weight:bold">from</span> <span style="color:#0e84b5;font-weight:bold">skimage</span> <span style="color:#007020;font-weight:bold">import</span> transform

net <span style="color:#666">=</span> InceptionV3()

<span style="color:#007020;font-weight:bold">def</span> <span style="color:#06287e">inception_predict</span>(image):
    <span style="color:#60a0b0;font-style:italic"># Rescale image to 299x299, as required by InceptionV3</span>
    image_prep <span style="color:#666">=</span> transform<span style="color:#666">.</span>resize(image, (<span style="color:#40a070">299</span>, <span style="color:#40a070">299</span>, <span style="color:#40a070">3</span>), mode<span style="color:#666">=</span><span style="color:#4070a0">&#39;reflect&#39;</span>)
    
    <span style="color:#60a0b0;font-style:italic"># Scale image values to [-1, 1], as required by InceptionV3</span>
    image_prep <span style="color:#666">=</span> (img_as_float(image_prep) <span style="color:#666">-</span> <span style="color:#40a070">0.5</span>) <span style="color:#666">*</span> <span style="color:#40a070">2</span>
    
    predictions <span style="color:#666">=</span> decode_predictions(
        net<span style="color:#666">.</span>predict(image_prep[None, <span style="color:#666">...</span>])
    )
    
    plt<span style="color:#666">.</span>imshow(image, cmap<span style="color:#666">=</span><span style="color:#4070a0">&#39;gray&#39;</span>)
    
    <span style="color:#007020;font-weight:bold">for</span> pred <span style="color:#007020;font-weight:bold">in</span> predictions[<span style="color:#40a070">0</span>]:
        (n, klass, prob) <span style="color:#666">=</span> pred
        <span style="color:#007020;font-weight:bold">print</span>(f<span style="color:#4070a0">&#39;{klass:&gt;15} ({prob:.3f})&#39;</span>)
</code></pre></div>







<figure>
    <img
        
            sizes="(min-width: 35em) 1200px, 100vw"
              
            srcset='
            
                   
            
                   
            
                   
            
                   
            '

            
            
            src="https://mentat.za.net/blog/2019/08/06/portland-microscopy/chelsea.png"
            

        /> <figcaption>
            <h4>Chelsea the Cat</h4>
        </figcaption>
</figure>

<p>For example, when running <code>inception_predict</code> on <code>skimage.data.chelsea()</code>, I get:</p>
<pre><code>Egyptian_cat (0.904)
       tabby (0.054)
   tiger_cat (0.035)
        lynx (0.000)
 plastic_bag (0.000)
</code></pre><p>Looks about right!</p>
<h2 id="imglyb">imglyb</h2>
<p>Philipp Hanslovsky, at SciPy2019, <a href="https://www.youtube.com/watch?v=Ddo5z5qGMb8">demonstrated his Python ↔ Java bridge</a> called <code>imglyb</code>.  In contrast to many previous efforts, this library allows you to <em>share memory</em> between Python and Java, avoiding costly (and, potentially fatal, dependent on memory constraints) reallocations.  E.g., he showed how to manipulate volumes of data (3-D arrays) in Python, and to then view those using ImageJ&rsquo;s impressive <a href="https://imagej.net/BigDataViewer">BigDataViewer</a>, which can rapidly slice through the volume at an arbitrary plane.</p>
<h2 id="lazy-viewing-of-data-using-dask">Lazy viewing of data using <code>dask</code></h2>
<p>This is a trick I borrowed from <a href="http://matthewrocklin.com/blog/work/2017/01/17/dask-images">Matt Rocklin&rsquo;s blog post</a>.</p>
<p>When you have a number of large images that, together, form a stack (3-D volume), it may not be possible to load the entire stack into memory.  Instead, you can use <code>dask</code> to lazily access parts of the volume on an as-needed basis.</p>
<p>This is achieved in four steps:</p>
<ol>
<li>
<p>Convert <code>skimage.io.imread</code> into a delayed function, i.e. instead of returning the image itself it returns a <code>dask</code> <code>Delayed</code> object (similar to a Future or a Promise), that can fetch the image when needed.</p>
</li>
<li>
<p>Use this function to load all images.  The operation is instantaneous, returning a list of <code>Delayed</code> objects.</p>
</li>
<li>
<p>Convert each <code>Delayed</code> object to a <code>dask</code> <code>Array</code>.</p>
</li>
<li>
<p>Stack all of these <code>dask</code> <code>Array</code>s to form the volume.</p>
</li>
</ol>
<p>Note that <em>each one</em> of these steps should execute almost instantaneously; no images files are accessed on disk: that only happens once we start operating on the <code>dask</code> <code>Array</code> volume.</p>
<p>Here is the code:</p>
<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#007020;font-weight:bold">from</span> <span style="color:#0e84b5;font-weight:bold">glob</span> <span style="color:#007020;font-weight:bold">import</span> glob

<span style="color:#007020;font-weight:bold">from</span> <span style="color:#0e84b5;font-weight:bold">dask</span> <span style="color:#007020;font-weight:bold">import</span> delayed
<span style="color:#007020;font-weight:bold">import</span> <span style="color:#0e84b5;font-weight:bold">dask.array</span> <span style="color:#007020;font-weight:bold">as</span> <span style="color:#0e84b5;font-weight:bold">da</span>

<span style="color:#007020;font-weight:bold">from</span> <span style="color:#0e84b5;font-weight:bold">skimage</span> <span style="color:#007020;font-weight:bold">import</span> io

<span style="color:#60a0b0;font-style:italic"># Read one image to get dimensions</span>
image <span style="color:#666">=</span> io<span style="color:#666">.</span>imread(<span style="color:#4070a0">&#39;samples/Test_TIRR_0_1p5_B0p2_01000.tiff&#39;</span>)

<span style="color:#60a0b0;font-style:italic"># Turn imread into a delayed function, so that it does not immediately</span>
<span style="color:#60a0b0;font-style:italic"># load an image file from disk</span>
imread <span style="color:#666">=</span> delayed(io<span style="color:#666">.</span>imread, pure<span style="color:#666">=</span>True)

<span style="color:#60a0b0;font-style:italic"># Create a list of all our samples; since a delayed version of `imread`</span>
<span style="color:#60a0b0;font-style:italic"># is used, no work is done immediately</span>
samples <span style="color:#666">=</span> [imread(f) <span style="color:#007020;font-weight:bold">for</span> f <span style="color:#007020;font-weight:bold">in</span> <span style="color:#007020">sorted</span>(glob(<span style="color:#4070a0">&#39;samples/*.tiff&#39;</span>))]

<span style="color:#60a0b0;font-style:italic"># Convert each &#34;delayed&#34; object in the list above into a dask array</span>
sample_arrays <span style="color:#666">=</span> [da<span style="color:#666">.</span>from_delayed(sample, shape<span style="color:#666">=</span>image<span style="color:#666">.</span>shape, dtype<span style="color:#666">=</span>np<span style="color:#666">.</span>uint8) <span style="color:#007020;font-weight:bold">for</span> sample <span style="color:#007020;font-weight:bold">in</span> samples]

<span style="color:#60a0b0;font-style:italic"># Stack all these arrays into a volume</span>
vol <span style="color:#666">=</span> da<span style="color:#666">.</span>stack(sample_arrays)
</code></pre></div><p>I have 101 slices of 2048x2048 each, so the resulting <code>dask</code> <code>Array</code> volume (at this stage fully virtual, without any data inside) is:</p>








<figure>
    <img
        
            sizes="(min-width: 35em) 1200px, 100vw"
              
            srcset='
            
                   https://mentat.za.net/blog/2019/08/06/portland-microscopy/dask-array-stack_hudcf8b4878943ce1b5f89d904b26d6a44_26566_480x0_resize_box_2.png 480w,
            
                   https://mentat.za.net/blog/2019/08/06/portland-microscopy/dask-array-stack_hudcf8b4878943ce1b5f89d904b26d6a44_26566_800x0_resize_box_2.png 800w,
            
                   
            
                   
            '

            
            
            src="https://mentat.za.net/blog/2019/08/06/portland-microscopy/dask-array-stack_hudcf8b4878943ce1b5f89d904b26d6a44_26566_800x0_resize_box_2.png"
            

         height="200"/> 
</figure>

<p>We can do numerous operations on this array, such as summing it with <code>vol.sum(axis=0)</code>, although this still yields an uncomputed <code>dask</code> <code>Array</code>.  To get actual values, we need to call:</p>
<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">vol<span style="color:#666">.</span>sum(axis<span style="color:#666">=</span><span style="color:#40a070">0</span>)<span style="color:#666">.</span>compute()
</code></pre></div><h2 id="napari">Napari</h2>
<p>To visualize a volume like the one above, I could have sliced into it and displayed the result using <code>matplotlib</code>.  However, I used this opportunity to play around with a brand new open source image viewer called <a href="https://github.com/napari/napari">Napari</a>.</p>
<p>Napari allows you to visualize layers interactively, similarly to GIMP or Photoshop.  In Napari&rsquo;s case, these layers can be images, labels, points, and a few others.</p>
<p>While this isn&rsquo;t explicitly documented (Napari is still in <a href="https://github.com/napari/napari/issues/467">alpha</a>!), I had some insider knowledge (👋 J!) that Napari supports both <code>dask</code> and <a href="https://zarr.readthedocs.io">Zarr</a> arrays.  So, we can pass in our volume from the example above as follows:</p>
<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#007020;font-weight:bold">import</span> <span style="color:#0e84b5;font-weight:bold">napari</span>

<span style="color:#007020;font-weight:bold">with</span> napari<span style="color:#666">.</span>gui_qt():
    viewer <span style="color:#666">=</span> napari<span style="color:#666">.</span>view(vol, clim_range<span style="color:#666">=</span>(<span style="color:#40a070">0</span>, <span style="color:#40a070">255</span>))
</code></pre></div><p>(Instead of the context manager, you may also use <code>%gui = qt</code> in Jupyter or IPython.)</p>
<p>I also happened to have ground truth labels available, so I loaded those up the same way I did the volume, and added it to the visualization:</p>
<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">viewer<span style="color:#666">.</span>add_labels(labels, name<span style="color:#666">=</span><span style="color:#4070a0">&#39;Labels&#39;</span>)
</code></pre></div>







<figure>
    <img
        
            sizes="(min-width: 35em) 1200px, 100vw"
              
            srcset='
            
                   https://mentat.za.net/blog/2019/08/06/portland-microscopy/napari-ct-volume_hu1f49f705645b1d6504d5c2bd42dc12b3_109127_480x0_resize_q75_box.jpg 480w,
            
                   https://mentat.za.net/blog/2019/08/06/portland-microscopy/napari-ct-volume_hu1f49f705645b1d6504d5c2bd42dc12b3_109127_800x0_resize_q75_box.jpg 800w,
            
                   https://mentat.za.net/blog/2019/08/06/portland-microscopy/napari-ct-volume_hu1f49f705645b1d6504d5c2bd42dc12b3_109127_1200x0_resize_q75_box.jpg 1200w,
            
                   
            '

            
            
            src="https://mentat.za.net/blog/2019/08/06/portland-microscopy/napari-ct-volume_hu1f49f705645b1d6504d5c2bd42dc12b3_109127_800x0_resize_q75_box.jpg"
            

        /> 
</figure>

<p>If you&rsquo;d like to play with Napari yourself, I have a <a href="https://gist.github.com/stefanv/7c296c26b0c3624746f4317bed6a3540">3D cell segmentation example available online</a>.</p>
<h2 id="community">Community</h2>
<p>Toward the conclusion of my talk, I emphasized the role of community in building healthy scientific software ecosystems.  In the end, it is <em>all about people</em>.  I briefly highlight two community groups:</p>
<ul>
<li>
<p><a href="https://pangeo.io/">PanGeo</a>, whom I think sets a great example of how to organize field-specific interest around existing open source tools, and building scalable online analysis platforms without reinventing the wheel.</p>
</li>
<li>
<p><a href="https://www.openmicroscopy.org/">OME</a>, the Open Microscopy Environment, who is leading the charge on open data exchange formats for microscopy.  Interestingly, it <a href="https://blog.openmicroscopy.org/community/file-formats/2019/06/25/formats/">looks like</a> <a href="https://zarr.readthedocs.io">Zarr</a>—the chunked, compressed array container—may well be part of the next open standard they recommend.</p>
</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>Thank you to the organizers of M&amp;M 2019 for inviting me to speak; I very much enjoyed our session, and look forward to working with this community on making scientific Python an <em>even better</em> platform for mirocroscopy analysis!</p>
]]></content>
            
                 
                
                 
                
                         
                        
                        
                            
                             
                                <category scheme="taxonomy:Tags" term="python" label="python" />
                             
                                <category scheme="taxonomy:Tags" term="scipy" label="scipy" />
                             
                                <category scheme="taxonomy:Tags" term="visualization" label="visualization" />
                             
                                <category scheme="taxonomy:Tags" term="image-processing" label="image processing" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[SciPy2013 Proceedings]]></title>
            <link href="https://mentat.za.net/blog/2013/06/27/scipy2013-proceedings/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://mentat.za.net/blog/2012/09/30/scikits-image-0-dot-7/?utm_source=atom_feed" rel="related" type="text/html" title="scikits-image 0.7" />
                <link href="https://mentat.za.net/blog/2012/09/25/emacs-package-management/?utm_source=atom_feed" rel="related" type="text/html" title="Emacs package management" />
                <link href="https://mentat.za.net/blog/2012/10/15/replicable-super-resolution-paper/?utm_source=atom_feed" rel="related" type="text/html" title="Replicable super-resolution paper" />
            
                <id>https://mentat.za.net/blog/2013/06/27/scipy2013-proceedings/</id>
            
            
            <published>2013-06-27T00:00:00+00:00</published>
            <updated>0001-01-01T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Where I announce the SciPy 2013 proceedings, and talk about how we did it.</blockquote><p>The talks for the 12th (fantastic) Python in Science conference just concluded,
and I am happy to announce the
<a href="https://dl.dropboxusercontent.com/u/380268/scipy_2013_proceedings_draft.pdf">conference proceedings</a>.</p>
<p>This may come as a surprize to some, since in the past we have been unable to
publish the proceedings in a timely manner.  So, what changed?</p>
<h2 id="review-process">Review process</h2>
<p>For 2013 we followed a <strong>very light-weight review process, via comments on
GitHub pull-requests</strong>.  This change has an important consequence: in contrast
to the traditional review process, where reviewers critically pull apart
papers, the process now changes into a constructive conversation&ndash;the reviewer
becomes an ally to the author, helping them to get their paper signed off on.</p>
<p>In addition, this is a very familiar process to most members of our community
who regularly collaborate to open source projects.  Most such projects nowadays
follow a similar methodology for discussing and integrating patches.</p>
<h2 id="tools">Tools</h2>
<p>Since we can&rsquo;t expect reviewers to check out and build the papers themselves, a
<a href="http://stefan.pythonanywhere.com">paper build bot</a> is provided to generate
PDFs from pull-requests, which contain papers in plain-text ReStructuredText
format (see the
<a href="https://github.com/scipy/scipy_proceedings/tree/2013">proceedings repository</a> for
examples, and all papers starting 2010).</p>
<p>For authors, tools are provided to convert the ReStructuredText papers to
PDFs in IEEE Computer Society paper style.</p>
<h2 id="help-us-with-the-final-review">Help us with the final review</h2>
<p>We welcome your feedback on the proceedings!  If you spot a mistake, please
submit a pull request on
<a href="https://github.com/scipy/scipy_proceedings/tree/2013">GitHub</a>.</p>
<h2 id="thanks">Thanks</h2>
<p>Finally, a big shout-out to the amazing team of people who organized this
year&rsquo;s conference, and to the wonderfully inclusive and talented Scientific
Python community, of which I am proud to be part of.</p>
]]></content>
            
                 
                
                 
                
                         
                        
                        
                            
                             
                                <category scheme="taxonomy:Tags" term="scipy" label="scipy" />
                             
                                <category scheme="taxonomy:Tags" term="python" label="python" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[scikits-image 0.7]]></title>
            <link href="https://mentat.za.net/blog/2012/09/30/scikits-image-0-dot-7/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://mentat.za.net/blog/2012/09/25/emacs-package-management/?utm_source=atom_feed" rel="related" type="text/html" title="Emacs package management" />
            
                <id>https://mentat.za.net/blog/2012/09/30/scikits-image-0-dot-7/</id>
            
            
            <published>2012-09-30T00:00:00+00:00</published>
            <updated>0001-01-01T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>We&rsquo;re happy to announce the 7th version of scikits-image!</p>
<p>Scikits-image is an image processing toolbox for SciPy that includes algorithms
for segmentation, geometric transformations, color space manipulation,
analysis, filtering, morphology, feature detection, and more.</p>
<p>For more information, examples, and documentation, please visit <a href="http://skimage.org">our website</a>.</p>
<h2 id="new-features">New Features</h2>
<p>It&rsquo;s been only 3 months since scikits-image 0.6 was released, but in that short
time, we&rsquo;ve managed to add plenty of new features and enhancements, including</p>
<ul>
<li>Geometric image transforms</li>
<li>3 new image segmentation routines (Felsenzwalb, Quickshift, SLIC)</li>
<li>Local binary patterns for texture characterization</li>
<li>Morphological reconstruction</li>
<li>Polygon approximation</li>
<li>CIE Lab color space conversion</li>
<li>Image pyramids</li>
<li>Multispectral support in random walker segmentation</li>
<li>Slicing, concatenation, and natural sorting of image collections</li>
<li>Perimeter and coordinates measurements in regionprops</li>
<li>An extensible image viewer based on Qt and Matplotlib, with plugins for edge
detection, line-profiling, and viewing image collections</li>
</ul>
<p>Plus, this release adds a number of bug fixes, new examples, and performance
enhancements.</p>








<figure>
    <img
        
            sizes="(min-width: 35em) 1200px, 100vw"
              
            srcset='
            
                   https://mentat.za.net/blog/2012/09/30/scikits-image-0-dot-7/lena_superpixels_hu6d489b99ce5d1ae95f2fbf5eee585e7c_146391_480x0_resize_q75_box.jpg 480w,
            
                   https://mentat.za.net/blog/2012/09/30/scikits-image-0-dot-7/lena_superpixels_hu6d489b99ce5d1ae95f2fbf5eee585e7c_146391_800x0_resize_q75_box.jpg 800w,
            
                   
            
                   
            '

            
            
            src="https://mentat.za.net/blog/2012/09/30/scikits-image-0-dot-7/lena_superpixels_hu6d489b99ce5d1ae95f2fbf5eee585e7c_146391_800x0_resize_q75_box.jpg"
            

        /> <figcaption>
            <h4>Comparison of pupular segmentation algorithms</h4>
        </figcaption>
</figure>

<h2 id="contributors-to-this-release">Contributors to this release</h2>
<p>This release was only possible due to the efforts of many contributors, both
new and old.</p>
<ul>
<li>Andreas Mueller</li>
<li>Andreas Wuerl</li>
<li>Andy Wilson</li>
<li>Brian Holt</li>
<li>Christoph Gohlke</li>
<li>Dharhas Pothina</li>
<li>Emmanuelle Gouillart</li>
<li>Guillaume Gay</li>
<li>Josh Warner</li>
<li>James Bergstra</li>
<li>Johannes Schönberger</li>
<li>Jonathan J. Helmus</li>
<li>Juan Nunez-Iglesias</li>
<li>Leon Tietz</li>
<li>Marianne Corvellec</li>
<li>Matt McCormick</li>
<li>Neil Yager</li>
<li>Nicolas Pinto</li>
<li>Nicolas Poilvert</li>
<li>Pavel Campr</li>
<li>Petter Strandmark</li>
<li>Stéfan van der Walt</li>
<li>Tim Sheerman-Chase</li>
<li>Tomas Kazmar</li>
<li>Tony S Yu</li>
<li>Wei Li</li>
</ul>
]]></content>
            
                 
                
                 
                
                         
                        
                        
                            
                             
                                <category scheme="taxonomy:Tags" term="image-processing" label="image processing" />
                             
                                <category scheme="taxonomy:Tags" term="scipy" label="scipy" />
                             
                                <category scheme="taxonomy:Tags" term="python" label="python" />
                             
                                <category scheme="taxonomy:Tags" term="science" label="science" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Emacs package management]]></title>
            <link href="https://mentat.za.net/blog/2012/09/25/emacs-package-management/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
            
                <id>https://mentat.za.net/blog/2012/09/25/emacs-package-management/</id>
            
            
            <published>2012-09-25T00:00:00+00:00</published>
            <updated>0001-01-01T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>I recently tried to install MuMaMo as one of the dependencies for Takafumi
Arakaki&rsquo;s <a href="https://github.com/tkf/emacs-ipython-notebook">Emacs-based IPython notebook</a>.  The instructions on the MuMaMo
webpage were as clear as mud and aimed primarily at Windows users.  Enters
<a href="https://github.com/dimitri/el-get">apt-get for Emacs</a>!</p>
<p>My Emacs setup is shared across multiple machines: a synchronized <code>elisp</code>
folder, containing <code>*.el</code> files, along with my <code>.emacs</code> configuration.
<code>el-get</code> allows you to share your package installation folder in a similar
fashion.  Here are some relevant configuration snippets:</p>
<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-common-lisp" data-lang="common-lisp">
<span style="color:#60a0b0;font-style:italic">; Everything gets installed into ~/elisp, a folder</span>
<span style="color:#60a0b0;font-style:italic">; I sync across all my machines</span>

(<span style="color:#007020;font-weight:bold">setq</span> <span style="color:#bb60d5">el-get-dir</span> <span style="color:#4070a0">&#34;~/elisp/el-get&#34;</span>)
(<span style="color:#007020;font-weight:bold">setq</span> <span style="color:#bb60d5">el-get-install-dir</span> <span style="color:#4070a0">&#34;~/elisp/el-get/el-get&#34;</span>)
(<span style="color:#bb60d5">add-to-list</span> <span style="color:#517918">&#39;load-path</span> <span style="color:#bb60d5">el-get-install-dir</span>)

<span style="color:#60a0b0;font-style:italic">; If el-get is missing, install it automatically</span>

(<span style="color:#007020">unless</span> (<span style="color:#06287e">require</span> <span style="color:#517918">&#39;el-get</span> <span style="color:#60add5">nil</span> <span style="color:#60add5">t</span>)
  (<span style="color:#bb60d5">url-retrieve</span>
   <span style="color:#4070a0">&#34;https://raw.github.com/dimitri/el-get/master/el-get-install.el&#34;</span>
   (<span style="color:#007020">lambda</span> (<span style="color:#bb60d5">s</span>)
     (<span style="color:#bb60d5">goto-char</span> (<span style="color:#bb60d5">point-max</span>))
     (<span style="color:#bb60d5">eval-print-last-sexp</span>))))

<span style="color:#60a0b0;font-style:italic">; Install these packages, and call the specified configuration snippets</span>
<span style="color:#60a0b0;font-style:italic">; after each load</span>
(<span style="color:#007020;font-weight:bold">setq</span> <span style="color:#bb60d5">el-get-sources</span>
      <span style="color:#666">&#39;</span>(

        (<span style="color:#517918">:name</span> <span style="color:#bb60d5">ethan-wspace</span>
         <span style="color:#517918">:after</span> (<span style="color:#007020;font-weight:bold">progn</span>
                  (<span style="color:#bb60d5">global-ethan-wspace-mode</span> <span style="color:#40a070">1</span>)
                  (<span style="color:#bb60d5">set-face-background</span> <span style="color:#517918">&#39;ethan-wspace-face</span> <span style="color:#4070a0">&#34;gray95&#34;</span>)))

        (<span style="color:#517918">:name</span> <span style="color:#bb60d5">column-marker</span>
         <span style="color:#517918">:after</span> (<span style="color:#bb60d5">add-hook</span> <span style="color:#517918">&#39;font-lock-mode-hook</span>
                          (<span style="color:#007020">lambda</span> () (<span style="color:#bb60d5">interactive</span>) (<span style="color:#bb60d5">column-marker-1</span> <span style="color:#40a070">80</span>))))

<span style="color:#60a0b0;font-style:italic">; Also install these packages, no configuration required</span>
(<span style="color:#007020;font-weight:bold">setq</span> <span style="color:#bb60d5">my-packages</span>
      (<span style="color:#06287e">append</span>
       <span style="color:#666">&#39;</span>(<span style="color:#bb60d5">el-get</span> <span style="color:#bb60d5">maxframe</span> <span style="color:#bb60d5">markdown-mode</span> <span style="color:#bb60d5">ein</span> <span style="color:#bb60d5">python</span>)
       (<span style="color:#06287e">mapcar</span> <span style="color:#517918">&#39;el-get-source-name</span> <span style="color:#bb60d5">el-get-sources</span>)
       )
)

<span style="color:#60a0b0;font-style:italic">; Check packages and install any that are missing</span>
(<span style="color:#bb60d5">el-get</span> <span style="color:#517918">&#39;sync</span> <span style="color:#bb60d5">my-packages</span>)
</code></pre></div><p>There are two ways to specify packages to be installed: either include them in
the <code>my-packages</code> list, or add them to <code>el-get-sources</code>, which in addition
allows further customization upon successful loading of the package.</p>
<p><a href="http://software-carpentry.org/2012/09/whats-in-your-stack/">What&rsquo;s in your stack?</a> Here&rsquo;s my list of Emacs packages:</p>
<pre><code>Org Mode, Ethan's wspace, Tab Bar, Column Marker, Max Frame, EIN, Python,
JS2
</code></pre>
<p>Do you know of any other useful packages?  Let me know!</p>
<!-- raw HTML omitted -->
]]></content>
            
                 
                
                 
                
                         
                        
                        
                            
                             
                                <category scheme="taxonomy:Tags" term="emacs" label="emacs" />
                             
                                <category scheme="taxonomy:Tags" term="python" label="python" />
                             
                                <category scheme="taxonomy:Tags" term="scipy" label="scipy" />
                            
                        
                    
                
            
        </entry>
    
</feed>
