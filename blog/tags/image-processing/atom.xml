<?xml version="1.0" encoding="utf-8"?> 
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en-us">
    <generator uri="https://gohugo.io/" version="0.80.0">Hugo</generator><title type="html"><![CDATA[image processing on Stéfan's blog]]></title>
    
    
    
            <link href="https://mentat.za.net/blog/tags/image-processing/" rel="alternate" type="text/html" title="HTML" />
            <link href="https://mentat.za.net/blog/tags/image-processing/atom.xml" rel="self" type="application/atom" title="atom" />
    <updated>2021-01-19T18:35:39-08:00</updated>
    
    
    <author>
            <name>Stéfan van der Walt</name>
            </author>
    
        <id>https://mentat.za.net/blog/tags/image-processing/</id>
    
        
        <entry>
            <title type="html"><![CDATA[Scientific Python at Microscopy & MicroAnalysis 2019]]></title>
            <link href="https://mentat.za.net/blog/2019/08/06/portland-microscopy/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://mentat.za.net/blog/2012/09/30/scikits-image-0-dot-7/?utm_source=atom_feed" rel="related" type="text/html" title="scikits-image 0.7" />
                <link href="https://mentat.za.net/blog/2013/06/27/scipy2013-proceedings/?utm_source=atom_feed" rel="related" type="text/html" title="SciPy2013 Proceedings" />
                <link href="https://mentat.za.net/blog/2012/09/25/emacs-package-management/?utm_source=atom_feed" rel="related" type="text/html" title="Emacs package management" />
                <link href="https://mentat.za.net/blog/2018/10/31/using-org-mode-with-neomutt/?utm_source=atom_feed" rel="related" type="text/html" title="Linking to emails in org-mode (using neomutt)" />
                <link href="https://mentat.za.net/blog/2016/10/20/websockets-in-python/?utm_source=atom_feed" rel="related" type="text/html" title="WebSockets in Python (and some Redux)" />
            
                <id>https://mentat.za.net/blog/2019/08/06/portland-microscopy/</id>
            
            
            <published>2019-08-06T00:00:00+00:00</published>
            <updated>0001-01-01T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Where we demonstrate a new way of doing interactive image analysis.</blockquote><p>Today, I presented a talk titled <a href="https://doi.org/10.1017/S1431927619001399">&ldquo;Scientific Python: A Mature Computational Ecosystem for Microscopy&rdquo;</a> [<a href="http://www.jhmartins.com/mm2019c/7337/0132.pdf">PDF</a>] at the Microscopy and MicroAnalysis conference in Portland.</p>
<p>A few members of the audience familiar with scientific Python told me they had learned something, so I&rsquo;ll highlight the few topics that I think may have qualified.</p>
<h2 id="scipy-10-paper">SciPy 1.0 paper</h2>
<p>The first official release of SciPy was in 2001, and a mere 16 years later we reached 1.0. This says a lot about the developer community, and how careful they are to label their own work as &ldquo;mature&rdquo;!  To celebrate this project milestone, we <a href="https://arxiv.org/abs/1907.10121">published a preprint on arXiv</a> that outlines the project history and its current status.  It mentions, among other achievements, that SciPy was instrumental in the first <a href="https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.119.161101">gravitational wave detection</a>, as well as the recent <a href="https://iopscience.iop.org/journal/2041-8205/page/Focus_on_EHT">imaging of the black hole in Messier 87</a>.</p>
<h2 id="numpy-__array_function__-protocol">NumPy <code>__array_function__</code> protocol</h2>
<p>The 1.17 release of NumPy (2019-07-26) has support for a <a href="https://numpy.org/neps/nep-0018-array-function-protocol.html">new array function protocol</a>, that allows external libraries to pass their array-like objects through NumPy without them being horribly mangled.  E.g., you may call NumPy&rsquo;s <code>sum</code> on a CuPy array: the computation will happen on the GPU, and the resulting array will still be a CuPy array.</p>
<p>Here is an example:</p>
<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">In [<span style="color:#40a070">24</span>]: <span style="color:#007020;font-weight:bold">import</span> <span style="color:#0e84b5;font-weight:bold">cupy</span> <span style="color:#007020;font-weight:bold">as</span> <span style="color:#0e84b5;font-weight:bold">cp</span>

In [<span style="color:#40a070">25</span>]: x <span style="color:#666">=</span> cp<span style="color:#666">.</span>random<span style="color:#666">.</span>random([<span style="color:#40a070">10</span>, <span style="color:#40a070">10</span>])

In [<span style="color:#40a070">26</span>]: y <span style="color:#666">=</span> x<span style="color:#666">.</span>sum(axis<span style="color:#666">=</span><span style="color:#40a070">0</span>)

In [<span style="color:#40a070">27</span>]: <span style="color:#007020">type</span>(y), y<span style="color:#666">.</span>shape
Out[<span style="color:#40a070">27</span>]: (cupy<span style="color:#666">.</span>core<span style="color:#666">.</span>core<span style="color:#666">.</span>ndarray, (<span style="color:#40a070">10</span>,))

In [<span style="color:#40a070">28</span>]: <span style="color:#007020;font-weight:bold">import</span> <span style="color:#0e84b5;font-weight:bold">numpy</span> <span style="color:#007020;font-weight:bold">as</span> <span style="color:#0e84b5;font-weight:bold">np</span>

In [<span style="color:#40a070">29</span>]: z <span style="color:#666">=</span> np<span style="color:#666">.</span>sum(x, axis<span style="color:#666">=</span><span style="color:#40a070">0</span>)

In [<span style="color:#40a070">30</span>]: <span style="color:#007020">type</span>(z), z<span style="color:#666">.</span>shape
Out[<span style="color:#40a070">30</span>]: (cupy<span style="color:#666">.</span>core<span style="color:#666">.</span>core<span style="color:#666">.</span>ndarray, (<span style="color:#40a070">10</span>,))
</code></pre></div><p>Note how the result is the same, whether you use CuPy or NumPy&rsquo;s <code>sum</code>.</p>
<p>Whereas NumPy used to be the reference implementation for array computation in Python, it is fast evolving into a standard API, implemented by multiple libraries.</p>
<h2 id="pytorch-and-tensorflow-easily-consume-python-images">PyTorch and TensorFlow easily consume Python images</h2>
<p>Images in scientific Python (<code>scikit-image</code>, <code>opencv</code>, etc.) are represented as NumPy arrays.  It is trivial to pass these arrays into deep learning libraries such as TensorFlow:</p>
<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">
<span style="color:#007020;font-weight:bold">from</span> <span style="color:#0e84b5;font-weight:bold">tensorflow.keras.applications.inception_v3</span> <span style="color:#007020;font-weight:bold">import</span> (
    InceptionV3, preprocess_input, decode_predictions
)
<span style="color:#007020;font-weight:bold">from</span> <span style="color:#0e84b5;font-weight:bold">skimage</span> <span style="color:#007020;font-weight:bold">import</span> transform

net <span style="color:#666">=</span> InceptionV3()

<span style="color:#007020;font-weight:bold">def</span> <span style="color:#06287e">inception_predict</span>(image):
    <span style="color:#60a0b0;font-style:italic"># Rescale image to 299x299, as required by InceptionV3</span>
    image_prep <span style="color:#666">=</span> transform<span style="color:#666">.</span>resize(image, (<span style="color:#40a070">299</span>, <span style="color:#40a070">299</span>, <span style="color:#40a070">3</span>), mode<span style="color:#666">=</span><span style="color:#4070a0">&#39;reflect&#39;</span>)
    
    <span style="color:#60a0b0;font-style:italic"># Scale image values to [-1, 1], as required by InceptionV3</span>
    image_prep <span style="color:#666">=</span> (img_as_float(image_prep) <span style="color:#666">-</span> <span style="color:#40a070">0.5</span>) <span style="color:#666">*</span> <span style="color:#40a070">2</span>
    
    predictions <span style="color:#666">=</span> decode_predictions(
        net<span style="color:#666">.</span>predict(image_prep[None, <span style="color:#666">...</span>])
    )
    
    plt<span style="color:#666">.</span>imshow(image, cmap<span style="color:#666">=</span><span style="color:#4070a0">&#39;gray&#39;</span>)
    
    <span style="color:#007020;font-weight:bold">for</span> pred <span style="color:#007020;font-weight:bold">in</span> predictions[<span style="color:#40a070">0</span>]:
        (n, klass, prob) <span style="color:#666">=</span> pred
        <span style="color:#007020;font-weight:bold">print</span>(f<span style="color:#4070a0">&#39;{klass:&gt;15} ({prob:.3f})&#39;</span>)
</code></pre></div>







<figure>
    <img
        
            sizes="(min-width: 35em) 1200px, 100vw"
              
            srcset='
            
                   
            
                   
            
                   
            
                   
            '

            
            
            src="https://mentat.za.net/blog/2019/08/06/portland-microscopy/chelsea.png"
            

        /> <figcaption>
            <h4>Chelsea the Cat</h4>
        </figcaption>
</figure>

<p>For example, when running <code>inception_predict</code> on <code>skimage.data.chelsea()</code>, I get:</p>
<pre><code>Egyptian_cat (0.904)
       tabby (0.054)
   tiger_cat (0.035)
        lynx (0.000)
 plastic_bag (0.000)
</code></pre><p>Looks about right!</p>
<h2 id="imglyb">imglyb</h2>
<p>Philipp Hanslovsky, at SciPy2019, <a href="https://www.youtube.com/watch?v=Ddo5z5qGMb8">demonstrated his Python ↔ Java bridge</a> called <code>imglyb</code>.  In contrast to many previous efforts, this library allows you to <em>share memory</em> between Python and Java, avoiding costly (and, potentially fatal, dependent on memory constraints) reallocations.  E.g., he showed how to manipulate volumes of data (3-D arrays) in Python, and to then view those using ImageJ&rsquo;s impressive <a href="https://imagej.net/BigDataViewer">BigDataViewer</a>, which can rapidly slice through the volume at an arbitrary plane.</p>
<h2 id="lazy-viewing-of-data-using-dask">Lazy viewing of data using <code>dask</code></h2>
<p>This is a trick I borrowed from <a href="http://matthewrocklin.com/blog/work/2017/01/17/dask-images">Matt Rocklin&rsquo;s blog post</a>.</p>
<p>When you have a number of large images that, together, form a stack (3-D volume), it may not be possible to load the entire stack into memory.  Instead, you can use <code>dask</code> to lazily access parts of the volume on an as-needed basis.</p>
<p>This is achieved in four steps:</p>
<ol>
<li>
<p>Convert <code>skimage.io.imread</code> into a delayed function, i.e. instead of returning the image itself it returns a <code>dask</code> <code>Delayed</code> object (similar to a Future or a Promise), that can fetch the image when needed.</p>
</li>
<li>
<p>Use this function to load all images.  The operation is instantaneous, returning a list of <code>Delayed</code> objects.</p>
</li>
<li>
<p>Convert each <code>Delayed</code> object to a <code>dask</code> <code>Array</code>.</p>
</li>
<li>
<p>Stack all of these <code>dask</code> <code>Array</code>s to form the volume.</p>
</li>
</ol>
<p>Note that <em>each one</em> of these steps should execute almost instantaneously; no images files are accessed on disk: that only happens once we start operating on the <code>dask</code> <code>Array</code> volume.</p>
<p>Here is the code:</p>
<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#007020;font-weight:bold">from</span> <span style="color:#0e84b5;font-weight:bold">glob</span> <span style="color:#007020;font-weight:bold">import</span> glob

<span style="color:#007020;font-weight:bold">from</span> <span style="color:#0e84b5;font-weight:bold">dask</span> <span style="color:#007020;font-weight:bold">import</span> delayed
<span style="color:#007020;font-weight:bold">import</span> <span style="color:#0e84b5;font-weight:bold">dask.array</span> <span style="color:#007020;font-weight:bold">as</span> <span style="color:#0e84b5;font-weight:bold">da</span>

<span style="color:#007020;font-weight:bold">from</span> <span style="color:#0e84b5;font-weight:bold">skimage</span> <span style="color:#007020;font-weight:bold">import</span> io

<span style="color:#60a0b0;font-style:italic"># Read one image to get dimensions</span>
image <span style="color:#666">=</span> io<span style="color:#666">.</span>imread(<span style="color:#4070a0">&#39;samples/Test_TIRR_0_1p5_B0p2_01000.tiff&#39;</span>)

<span style="color:#60a0b0;font-style:italic"># Turn imread into a delayed function, so that it does not immediately</span>
<span style="color:#60a0b0;font-style:italic"># load an image file from disk</span>
imread <span style="color:#666">=</span> delayed(io<span style="color:#666">.</span>imread, pure<span style="color:#666">=</span>True)

<span style="color:#60a0b0;font-style:italic"># Create a list of all our samples; since a delayed version of `imread`</span>
<span style="color:#60a0b0;font-style:italic"># is used, no work is done immediately</span>
samples <span style="color:#666">=</span> [imread(f) <span style="color:#007020;font-weight:bold">for</span> f <span style="color:#007020;font-weight:bold">in</span> <span style="color:#007020">sorted</span>(glob(<span style="color:#4070a0">&#39;samples/*.tiff&#39;</span>))]

<span style="color:#60a0b0;font-style:italic"># Convert each &#34;delayed&#34; object in the list above into a dask array</span>
sample_arrays <span style="color:#666">=</span> [da<span style="color:#666">.</span>from_delayed(sample, shape<span style="color:#666">=</span>image<span style="color:#666">.</span>shape, dtype<span style="color:#666">=</span>np<span style="color:#666">.</span>uint8) <span style="color:#007020;font-weight:bold">for</span> sample <span style="color:#007020;font-weight:bold">in</span> samples]

<span style="color:#60a0b0;font-style:italic"># Stack all these arrays into a volume</span>
vol <span style="color:#666">=</span> da<span style="color:#666">.</span>stack(sample_arrays)
</code></pre></div><p>I have 101 slices of 2048x2048 each, so the resulting <code>dask</code> <code>Array</code> volume (at this stage fully virtual, without any data inside) is:</p>








<figure>
    <img
        
            sizes="(min-width: 35em) 1200px, 100vw"
              
            srcset='
            
                   https://mentat.za.net/blog/2019/08/06/portland-microscopy/dask-array-stack_hudcf8b4878943ce1b5f89d904b26d6a44_26566_480x0_resize_box_2.png 480w,
            
                   https://mentat.za.net/blog/2019/08/06/portland-microscopy/dask-array-stack_hudcf8b4878943ce1b5f89d904b26d6a44_26566_800x0_resize_box_2.png 800w,
            
                   
            
                   
            '

            
            
            src="https://mentat.za.net/blog/2019/08/06/portland-microscopy/dask-array-stack_hudcf8b4878943ce1b5f89d904b26d6a44_26566_800x0_resize_box_2.png"
            

         height="200"/> 
</figure>

<p>We can do numerous operations on this array, such as summing it with <code>vol.sum(axis=0)</code>, although this still yields an uncomputed <code>dask</code> <code>Array</code>.  To get actual values, we need to call:</p>
<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">vol<span style="color:#666">.</span>sum(axis<span style="color:#666">=</span><span style="color:#40a070">0</span>)<span style="color:#666">.</span>compute()
</code></pre></div><h2 id="napari">Napari</h2>
<p>To visualize a volume like the one above, I could have sliced into it and displayed the result using <code>matplotlib</code>.  However, I used this opportunity to play around with a brand new open source image viewer called <a href="https://github.com/napari/napari">Napari</a>.</p>
<p>Napari allows you to visualize layers interactively, similarly to GIMP or Photoshop.  In Napari&rsquo;s case, these layers can be images, labels, points, and a few others.</p>
<p>While this isn&rsquo;t explicitly documented (Napari is still in <a href="https://github.com/napari/napari/issues/467">alpha</a>!), I had some insider knowledge (👋 J!) that Napari supports both <code>dask</code> and <a href="https://zarr.readthedocs.io">Zarr</a> arrays.  So, we can pass in our volume from the example above as follows:</p>
<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#007020;font-weight:bold">import</span> <span style="color:#0e84b5;font-weight:bold">napari</span>

<span style="color:#007020;font-weight:bold">with</span> napari<span style="color:#666">.</span>gui_qt():
    viewer <span style="color:#666">=</span> napari<span style="color:#666">.</span>view(vol, clim_range<span style="color:#666">=</span>(<span style="color:#40a070">0</span>, <span style="color:#40a070">255</span>))
</code></pre></div><p>(Instead of the context manager, you may also use <code>%gui = qt</code> in Jupyter or IPython.)</p>
<p>I also happened to have ground truth labels available, so I loaded those up the same way I did the volume, and added it to the visualization:</p>
<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">viewer<span style="color:#666">.</span>add_labels(labels, name<span style="color:#666">=</span><span style="color:#4070a0">&#39;Labels&#39;</span>)
</code></pre></div>







<figure>
    <img
        
            sizes="(min-width: 35em) 1200px, 100vw"
              
            srcset='
            
                   https://mentat.za.net/blog/2019/08/06/portland-microscopy/napari-ct-volume_hu1f49f705645b1d6504d5c2bd42dc12b3_109127_480x0_resize_q75_box.jpg 480w,
            
                   https://mentat.za.net/blog/2019/08/06/portland-microscopy/napari-ct-volume_hu1f49f705645b1d6504d5c2bd42dc12b3_109127_800x0_resize_q75_box.jpg 800w,
            
                   https://mentat.za.net/blog/2019/08/06/portland-microscopy/napari-ct-volume_hu1f49f705645b1d6504d5c2bd42dc12b3_109127_1200x0_resize_q75_box.jpg 1200w,
            
                   
            '

            
            
            src="https://mentat.za.net/blog/2019/08/06/portland-microscopy/napari-ct-volume_hu1f49f705645b1d6504d5c2bd42dc12b3_109127_800x0_resize_q75_box.jpg"
            

        /> 
</figure>

<p>If you&rsquo;d like to play with Napari yourself, I have a <a href="https://gist.github.com/stefanv/7c296c26b0c3624746f4317bed6a3540">3D cell segmentation example available online</a>.</p>
<h2 id="community">Community</h2>
<p>Toward the conclusion of my talk, I emphasized the role of community in building healthy scientific software ecosystems.  In the end, it is <em>all about people</em>.  I briefly highlight two community groups:</p>
<ul>
<li>
<p><a href="https://pangeo.io/">PanGeo</a>, whom I think sets a great example of how to organize field-specific interest around existing open source tools, and building scalable online analysis platforms without reinventing the wheel.</p>
</li>
<li>
<p><a href="https://www.openmicroscopy.org/">OME</a>, the Open Microscopy Environment, who is leading the charge on open data exchange formats for microscopy.  Interestingly, it <a href="https://blog.openmicroscopy.org/community/file-formats/2019/06/25/formats/">looks like</a> <a href="https://zarr.readthedocs.io">Zarr</a>—the chunked, compressed array container—may well be part of the next open standard they recommend.</p>
</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>Thank you to the organizers of M&amp;M 2019 for inviting me to speak; I very much enjoyed our session, and look forward to working with this community on making scientific Python an <em>even better</em> platform for mirocroscopy analysis!</p>
]]></content>
            
                 
                
                 
                
                         
                        
                        
                            
                             
                                <category scheme="taxonomy:Tags" term="python" label="python" />
                             
                                <category scheme="taxonomy:Tags" term="scipy" label="scipy" />
                             
                                <category scheme="taxonomy:Tags" term="visualization" label="visualization" />
                             
                                <category scheme="taxonomy:Tags" term="image-processing" label="image processing" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Replicable super-resolution paper]]></title>
            <link href="https://mentat.za.net/blog/2012/10/15/replicable-super-resolution-paper/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://mentat.za.net/blog/2012/09/30/scikits-image-0-dot-7/?utm_source=atom_feed" rel="related" type="text/html" title="scikits-image 0.7" />
                <link href="https://mentat.za.net/blog/2012/09/25/emacs-package-management/?utm_source=atom_feed" rel="related" type="text/html" title="Emacs package management" />
            
                <id>https://mentat.za.net/blog/2012/10/15/replicable-super-resolution-paper/</id>
            
            
            <published>2012-10-15T00:00:00+00:00</published>
            <updated>0001-01-01T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Where I summarize 5 years of my life in 10 pages.</blockquote><p>While I loved the topic of my PhD, I had to take a break after staring at that
problem for several years.  Thereafter, I was side-tracked by
<a href="http://github.com/scipy">several</a> <a href="http://scikit-image.org">other</a>
<a href="http://dipy.org">projects</a>, and never got around to publishing a paper on
<a href="http://mentat.za.net/phd_dissertation.html">my dissertation</a>.</p>
<p>Here, then, is a summary of the simple but effective super-resolution algorithm
described therein:</p>
<p><a href="http://arxiv.org/abs/1210.3404">http://arxiv.org/abs/1210.3404</a></p>
<p>I also submitted this work to NIPS: the reviewers liked the paper, but they
were not convinced of its novelty.  Having spent a lot of time studying the
existing literature, all I can say in response is that, while solving the
problem as a sparse linear system was well known at the time, phrasing Drizzle
as a linear operator and using it for super-resolution was not.</p>
<p>But the proof of the pudding is in the eating! Have a look at the
<a href="http://mentat.za.net/supreme">results and published code</a> &ndash; you can download it all (including a
sample data-set) and play with the different reconstruction parameters.  Quite
a bit of the code has since graduated into <a href="http://scikit-image.org">scikit-image</a>.</p>
]]></content>
            
                 
                
                 
                
                         
                        
                        
                            
                             
                                <category scheme="taxonomy:Tags" term="super-resolution" label="super-resolution" />
                             
                                <category scheme="taxonomy:Tags" term="image-processing" label="image-processing" />
                             
                                <category scheme="taxonomy:Tags" term="python" label="python" />
                             
                                <category scheme="taxonomy:Tags" term="science" label="science" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[scikits-image 0.7]]></title>
            <link href="https://mentat.za.net/blog/2012/09/30/scikits-image-0-dot-7/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://mentat.za.net/blog/2012/09/25/emacs-package-management/?utm_source=atom_feed" rel="related" type="text/html" title="Emacs package management" />
            
                <id>https://mentat.za.net/blog/2012/09/30/scikits-image-0-dot-7/</id>
            
            
            <published>2012-09-30T00:00:00+00:00</published>
            <updated>0001-01-01T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>We&rsquo;re happy to announce the 7th version of scikits-image!</p>
<p>Scikits-image is an image processing toolbox for SciPy that includes algorithms
for segmentation, geometric transformations, color space manipulation,
analysis, filtering, morphology, feature detection, and more.</p>
<p>For more information, examples, and documentation, please visit <a href="http://skimage.org">our website</a>.</p>
<h2 id="new-features">New Features</h2>
<p>It&rsquo;s been only 3 months since scikits-image 0.6 was released, but in that short
time, we&rsquo;ve managed to add plenty of new features and enhancements, including</p>
<ul>
<li>Geometric image transforms</li>
<li>3 new image segmentation routines (Felsenzwalb, Quickshift, SLIC)</li>
<li>Local binary patterns for texture characterization</li>
<li>Morphological reconstruction</li>
<li>Polygon approximation</li>
<li>CIE Lab color space conversion</li>
<li>Image pyramids</li>
<li>Multispectral support in random walker segmentation</li>
<li>Slicing, concatenation, and natural sorting of image collections</li>
<li>Perimeter and coordinates measurements in regionprops</li>
<li>An extensible image viewer based on Qt and Matplotlib, with plugins for edge
detection, line-profiling, and viewing image collections</li>
</ul>
<p>Plus, this release adds a number of bug fixes, new examples, and performance
enhancements.</p>








<figure>
    <img
        
            sizes="(min-width: 35em) 1200px, 100vw"
              
            srcset='
            
                   https://mentat.za.net/blog/2012/09/30/scikits-image-0-dot-7/lena_superpixels_hu6d489b99ce5d1ae95f2fbf5eee585e7c_146391_480x0_resize_q75_box.jpg 480w,
            
                   https://mentat.za.net/blog/2012/09/30/scikits-image-0-dot-7/lena_superpixels_hu6d489b99ce5d1ae95f2fbf5eee585e7c_146391_800x0_resize_q75_box.jpg 800w,
            
                   
            
                   
            '

            
            
            src="https://mentat.za.net/blog/2012/09/30/scikits-image-0-dot-7/lena_superpixels_hu6d489b99ce5d1ae95f2fbf5eee585e7c_146391_800x0_resize_q75_box.jpg"
            

        /> <figcaption>
            <h4>Comparison of pupular segmentation algorithms</h4>
        </figcaption>
</figure>

<h2 id="contributors-to-this-release">Contributors to this release</h2>
<p>This release was only possible due to the efforts of many contributors, both
new and old.</p>
<ul>
<li>Andreas Mueller</li>
<li>Andreas Wuerl</li>
<li>Andy Wilson</li>
<li>Brian Holt</li>
<li>Christoph Gohlke</li>
<li>Dharhas Pothina</li>
<li>Emmanuelle Gouillart</li>
<li>Guillaume Gay</li>
<li>Josh Warner</li>
<li>James Bergstra</li>
<li>Johannes Schönberger</li>
<li>Jonathan J. Helmus</li>
<li>Juan Nunez-Iglesias</li>
<li>Leon Tietz</li>
<li>Marianne Corvellec</li>
<li>Matt McCormick</li>
<li>Neil Yager</li>
<li>Nicolas Pinto</li>
<li>Nicolas Poilvert</li>
<li>Pavel Campr</li>
<li>Petter Strandmark</li>
<li>Stéfan van der Walt</li>
<li>Tim Sheerman-Chase</li>
<li>Tomas Kazmar</li>
<li>Tony S Yu</li>
<li>Wei Li</li>
</ul>
]]></content>
            
                 
                
                 
                
                         
                        
                        
                            
                             
                                <category scheme="taxonomy:Tags" term="image-processing" label="image processing" />
                             
                                <category scheme="taxonomy:Tags" term="scipy" label="scipy" />
                             
                                <category scheme="taxonomy:Tags" term="python" label="python" />
                             
                                <category scheme="taxonomy:Tags" term="science" label="science" />
                            
                        
                    
                
            
        </entry>
    
</feed>
