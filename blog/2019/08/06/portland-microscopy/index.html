<!DOCTYPE html>
<html lang="en-us">
    <head>
		<meta charset="UTF-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
			<meta name="description" content="Where we demonstrate a new way of doing interactive image analysis.">

		<title>Scientific Python at Microscopy &amp; MicroAnalysis 2019 &middot; StÃ©fan&#39;s blog</title>

		
  		<link rel="stylesheet" href="/blog/css/style.css">
		<link rel="stylesheet" href="/blog/css/fonts.css">
		<link rel="stylesheet" href="/blog/custom.css">
		
		<link rel="icon" type="image/png" sizes="32x32" href="/blog/images/favicon-32x32.png">
		<link rel="icon" type="image/png" sizes="16x16" href="/blog/images/favicon-16x16.png">
		<link rel="apple-touch-icon" sizes="180x180" href="/blog/images/apple-touch-icon.png">

		
		<link href="" rel="alternate" type="application/rss+xml" title="StÃ©fan&#39;s blog" />
	</head>

    <body>
        		<nav class="nav">
			<div class="nav-container">
				<a href="/blog/">
					<h2 class="nav-title">StÃ©fan&#39;s blog</h2>
				</a>
				<ul>
    <li><a href="https://mentat.za.net">mentat.za.net</a></li>
    <li><a href="/blog/atom.xml">Atom / RSS feed</a></li>
</ul>

			</div>
		</nav>

        

<main>
	<div class="post">
		<div class="post-info">
</div>

		<h1 class="post-title">Scientific Python at Microscopy &amp; MicroAnalysis 2019</h1>

<div class="post-date">
  
    August 6, 2019
  
</div>

<div class="post-tags">
  
    <div class="post-tag">
      <a href=/blog/tags/python>
        #python
      </a>
    </div>
  
    <div class="post-tag">
      <a href=/blog/tags/scipy>
        #scipy
      </a>
    </div>
  
    <div class="post-tag">
      <a href=/blog/tags/visualization>
        #visualization
      </a>
    </div>
  
    <div class="post-tag">
      <a href=/blog/tags/image%20processing>
        #image processing
      </a>
    </div>
  
</div>


		

		<p>Today, I presented a talk titled <a href="https://doi.org/10.1017/S1431927619001399">&ldquo;Scientific Python: A Mature Computational Ecosystem for Microscopy&rdquo;</a> [<a href="http://www.jhmartins.com/mm2019c/7337/0132.pdf">PDF</a>] at the Microscopy and MicroAnalysis conference in Portland.</p>
<p>A few members of the audience familiar with scientific Python told me they had learned something, so I&rsquo;ll highlight the few topics that I think may have qualified.</p>
<h2 id="scipy-10-paper">SciPy 1.0 paper</h2>
<p>The first official release of SciPy was in 2001, and a mere 16 years later we reached 1.0. This says a lot about the developer community, and how careful they are to label their own work as &ldquo;mature&rdquo;!  To celebrate this project milestone, we <a href="https://arxiv.org/abs/1907.10121">published a preprint on arXiv</a> that outlines the project history and its current status.  It mentions, among other achievements, that SciPy was instrumental in the first <a href="https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.119.161101">gravitational wave detection</a>, as well as the recent <a href="https://iopscience.iop.org/journal/2041-8205/page/Focus_on_EHT">imaging of the black hole in Messier 87</a>.</p>
<h2 id="numpy-__array_function__-protocol">NumPy <code>__array_function__</code> protocol</h2>
<p>The 1.17 release of NumPy (2019-07-26) has support for a <a href="https://numpy.org/neps/nep-0018-array-function-protocol.html">new array function protocol</a>, that allows external libraries to pass their array-like objects through NumPy without them being horribly mangled.  E.g., you may call NumPy&rsquo;s <code>sum</code> on a CuPy array: the computation will happen on the GPU, and the resulting array will still be a CuPy array.</p>
<p>Here is an example:</p>
<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">In [<span style="color:#40a070">24</span>]: <span style="color:#007020;font-weight:bold">import</span> <span style="color:#0e84b5;font-weight:bold">cupy</span> <span style="color:#007020;font-weight:bold">as</span> <span style="color:#0e84b5;font-weight:bold">cp</span>

In [<span style="color:#40a070">25</span>]: x <span style="color:#666">=</span> cp<span style="color:#666">.</span>random<span style="color:#666">.</span>random([<span style="color:#40a070">10</span>, <span style="color:#40a070">10</span>])

In [<span style="color:#40a070">26</span>]: y <span style="color:#666">=</span> x<span style="color:#666">.</span>sum(axis<span style="color:#666">=</span><span style="color:#40a070">0</span>)

In [<span style="color:#40a070">27</span>]: <span style="color:#007020">type</span>(y), y<span style="color:#666">.</span>shape
Out[<span style="color:#40a070">27</span>]: (cupy<span style="color:#666">.</span>core<span style="color:#666">.</span>core<span style="color:#666">.</span>ndarray, (<span style="color:#40a070">10</span>,))

In [<span style="color:#40a070">28</span>]: <span style="color:#007020;font-weight:bold">import</span> <span style="color:#0e84b5;font-weight:bold">numpy</span> <span style="color:#007020;font-weight:bold">as</span> <span style="color:#0e84b5;font-weight:bold">np</span>

In [<span style="color:#40a070">29</span>]: z <span style="color:#666">=</span> np<span style="color:#666">.</span>sum(x, axis<span style="color:#666">=</span><span style="color:#40a070">0</span>)

In [<span style="color:#40a070">30</span>]: <span style="color:#007020">type</span>(z), z<span style="color:#666">.</span>shape
Out[<span style="color:#40a070">30</span>]: (cupy<span style="color:#666">.</span>core<span style="color:#666">.</span>core<span style="color:#666">.</span>ndarray, (<span style="color:#40a070">10</span>,))
</code></pre></div><p>Note how the result is the same, whether you use CuPy or NumPy&rsquo;s <code>sum</code>.</p>
<p>Whereas NumPy used to be the reference implementation for array computation in Python, it is fast evolving into a standard API, implemented by multiple libraries.</p>
<h2 id="pytorch-and-tensorflow-easily-consume-python-images">PyTorch and TensorFlow easily consume Python images</h2>
<p>Images in scientific Python (<code>scikit-image</code>, <code>opencv</code>, etc.) are represented as NumPy arrays.  It is trivial to pass these arrays into deep learning libraries such as TensorFlow:</p>
<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">
<span style="color:#007020;font-weight:bold">from</span> <span style="color:#0e84b5;font-weight:bold">tensorflow.keras.applications.inception_v3</span> <span style="color:#007020;font-weight:bold">import</span> (
    InceptionV3, preprocess_input, decode_predictions
)
<span style="color:#007020;font-weight:bold">from</span> <span style="color:#0e84b5;font-weight:bold">skimage</span> <span style="color:#007020;font-weight:bold">import</span> transform

net <span style="color:#666">=</span> InceptionV3()

<span style="color:#007020;font-weight:bold">def</span> <span style="color:#06287e">inception_predict</span>(image):
    <span style="color:#60a0b0;font-style:italic"># Rescale image to 299x299, as required by InceptionV3</span>
    image_prep <span style="color:#666">=</span> transform<span style="color:#666">.</span>resize(image, (<span style="color:#40a070">299</span>, <span style="color:#40a070">299</span>, <span style="color:#40a070">3</span>), mode<span style="color:#666">=</span><span style="color:#4070a0">&#39;reflect&#39;</span>)
    
    <span style="color:#60a0b0;font-style:italic"># Scale image values to [-1, 1], as required by InceptionV3</span>
    image_prep <span style="color:#666">=</span> (img_as_float(image_prep) <span style="color:#666">-</span> <span style="color:#40a070">0.5</span>) <span style="color:#666">*</span> <span style="color:#40a070">2</span>
    
    predictions <span style="color:#666">=</span> decode_predictions(
        net<span style="color:#666">.</span>predict(image_prep[None, <span style="color:#666">...</span>])
    )
    
    plt<span style="color:#666">.</span>imshow(image, cmap<span style="color:#666">=</span><span style="color:#4070a0">&#39;gray&#39;</span>)
    
    <span style="color:#007020;font-weight:bold">for</span> pred <span style="color:#007020;font-weight:bold">in</span> predictions[<span style="color:#40a070">0</span>]:
        (n, klass, prob) <span style="color:#666">=</span> pred
        <span style="color:#007020;font-weight:bold">print</span>(f<span style="color:#4070a0">&#39;{klass:&gt;15} ({prob:.3f})&#39;</span>)
</code></pre></div>







<figure>
    <img
        
            sizes="(min-width: 35em) 1200px, 100vw"
              
            srcset='
            
                   
            
                   
            
                   
            
                   
            '

            
            
            src="https://mentat.za.net/blog/2019/08/06/portland-microscopy/chelsea.png"
            

        /> <figcaption>
            <h4>Chelsea the Cat</h4>
        </figcaption>
</figure>

<p>For example, when running <code>inception_predict</code> on <code>skimage.data.chelsea()</code>, I get:</p>
<pre><code>Egyptian_cat (0.904)
       tabby (0.054)
   tiger_cat (0.035)
        lynx (0.000)
 plastic_bag (0.000)
</code></pre><p>Looks about right!</p>
<h2 id="imglyb">imglyb</h2>
<p>Philipp Hanslovsky, at SciPy2019, <a href="https://www.youtube.com/watch?v=Ddo5z5qGMb8">demonstrated his Python â†” Java bridge</a> called <code>imglyb</code>.  In contrast to many previous efforts, this library allows you to <em>share memory</em> between Python and Java, avoiding costly (and, potentially fatal, dependent on memory constraints) reallocations.  E.g., he showed how to manipulate volumes of data (3-D arrays) in Python, and to then view those using ImageJ&rsquo;s impressive <a href="https://imagej.net/BigDataViewer">BigDataViewer</a>, which can rapidly slice through the volume at an arbitrary plane.</p>
<h2 id="lazy-viewing-of-data-using-dask">Lazy viewing of data using <code>dask</code></h2>
<p>This is a trick I borrowed from <a href="http://matthewrocklin.com/blog/work/2017/01/17/dask-images">Matt Rocklin&rsquo;s blog post</a>.</p>
<p>When you have a number of large images that, together, form a stack (3-D volume), it may not be possible to load the entire stack into memory.  Instead, you can use <code>dask</code> to lazily access parts of the volume on an as-needed basis.</p>
<p>This is achieved in four steps:</p>
<ol>
<li>
<p>Convert <code>skimage.io.imread</code> into a delayed function, i.e. instead of returning the image itself it returns a <code>dask</code> <code>Delayed</code> object (similar to a Future or a Promise), that can fetch the image when needed.</p>
</li>
<li>
<p>Use this function to load all images.  The operation is instantaneous, returning a list of <code>Delayed</code> objects.</p>
</li>
<li>
<p>Convert each <code>Delayed</code> object to a <code>dask</code> <code>Array</code>.</p>
</li>
<li>
<p>Stack all of these <code>dask</code> <code>Array</code>s to form the volume.</p>
</li>
</ol>
<p>Note that <em>each one</em> of these steps should execute almost instantaneously; no images files are accessed on disk: that only happens once we start operating on the <code>dask</code> <code>Array</code> volume.</p>
<p>Here is the code:</p>
<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#007020;font-weight:bold">from</span> <span style="color:#0e84b5;font-weight:bold">glob</span> <span style="color:#007020;font-weight:bold">import</span> glob

<span style="color:#007020;font-weight:bold">from</span> <span style="color:#0e84b5;font-weight:bold">dask</span> <span style="color:#007020;font-weight:bold">import</span> delayed
<span style="color:#007020;font-weight:bold">import</span> <span style="color:#0e84b5;font-weight:bold">dask.array</span> <span style="color:#007020;font-weight:bold">as</span> <span style="color:#0e84b5;font-weight:bold">da</span>

<span style="color:#007020;font-weight:bold">from</span> <span style="color:#0e84b5;font-weight:bold">skimage</span> <span style="color:#007020;font-weight:bold">import</span> io

<span style="color:#60a0b0;font-style:italic"># Read one image to get dimensions</span>
image <span style="color:#666">=</span> io<span style="color:#666">.</span>imread(<span style="color:#4070a0">&#39;samples/Test_TIRR_0_1p5_B0p2_01000.tiff&#39;</span>)

<span style="color:#60a0b0;font-style:italic"># Turn imread into a delayed function, so that it does not immediately</span>
<span style="color:#60a0b0;font-style:italic"># load an image file from disk</span>
imread <span style="color:#666">=</span> delayed(io<span style="color:#666">.</span>imread, pure<span style="color:#666">=</span>True)

<span style="color:#60a0b0;font-style:italic"># Create a list of all our samples; since a delayed version of `imread`</span>
<span style="color:#60a0b0;font-style:italic"># is used, no work is done immediately</span>
samples <span style="color:#666">=</span> [imread(f) <span style="color:#007020;font-weight:bold">for</span> f <span style="color:#007020;font-weight:bold">in</span> <span style="color:#007020">sorted</span>(glob(<span style="color:#4070a0">&#39;samples/*.tiff&#39;</span>))]

<span style="color:#60a0b0;font-style:italic"># Convert each &#34;delayed&#34; object in the list above into a dask array</span>
sample_arrays <span style="color:#666">=</span> [da<span style="color:#666">.</span>from_delayed(sample, shape<span style="color:#666">=</span>image<span style="color:#666">.</span>shape, dtype<span style="color:#666">=</span>np<span style="color:#666">.</span>uint8) <span style="color:#007020;font-weight:bold">for</span> sample <span style="color:#007020;font-weight:bold">in</span> samples]

<span style="color:#60a0b0;font-style:italic"># Stack all these arrays into a volume</span>
vol <span style="color:#666">=</span> da<span style="color:#666">.</span>stack(sample_arrays)
</code></pre></div><p>I have 101 slices of 2048x2048 each, so the resulting <code>dask</code> <code>Array</code> volume (at this stage fully virtual, without any data inside) is:</p>








<figure>
    <img
        
            sizes="(min-width: 35em) 1200px, 100vw"
              
            srcset='
            
                   https://mentat.za.net/blog/2019/08/06/portland-microscopy/dask-array-stack_hudcf8b4878943ce1b5f89d904b26d6a44_26566_480x0_resize_box_2.png 480w,
            
                   https://mentat.za.net/blog/2019/08/06/portland-microscopy/dask-array-stack_hudcf8b4878943ce1b5f89d904b26d6a44_26566_800x0_resize_box_2.png 800w,
            
                   
            
                   
            '

            
            
            src="https://mentat.za.net/blog/2019/08/06/portland-microscopy/dask-array-stack_hudcf8b4878943ce1b5f89d904b26d6a44_26566_800x0_resize_box_2.png"
            

         height="200"/> 
</figure>

<p>We can do numerous operations on this array, such as summing it with <code>vol.sum(axis=0)</code>, although this still yields an uncomputed <code>dask</code> <code>Array</code>.  To get actual values, we need to call:</p>
<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">vol<span style="color:#666">.</span>sum(axis<span style="color:#666">=</span><span style="color:#40a070">0</span>)<span style="color:#666">.</span>compute()
</code></pre></div><h2 id="napari">Napari</h2>
<p>To visualize a volume like the one above, I could have sliced into it and displayed the result using <code>matplotlib</code>.  However, I used this opportunity to play around with a brand new open source image viewer called <a href="https://github.com/napari/napari">Napari</a>.</p>
<p>Napari allows you to visualize layers interactively, similarly to GIMP or Photoshop.  In Napari&rsquo;s case, these layers can be images, labels, points, and a few others.</p>
<p>While this isn&rsquo;t explicitly documented (Napari is still in <a href="https://github.com/napari/napari/issues/467">alpha</a>!), I had some insider knowledge (ðŸ‘‹ J!) that Napari supports both <code>dask</code> and <a href="https://zarr.readthedocs.io">Zarr</a> arrays.  So, we can pass in our volume from the example above as follows:</p>
<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#007020;font-weight:bold">import</span> <span style="color:#0e84b5;font-weight:bold">napari</span>

<span style="color:#007020;font-weight:bold">with</span> napari<span style="color:#666">.</span>gui_qt():
    viewer <span style="color:#666">=</span> napari<span style="color:#666">.</span>view(vol, clim_range<span style="color:#666">=</span>(<span style="color:#40a070">0</span>, <span style="color:#40a070">255</span>))
</code></pre></div><p>(Instead of the context manager, you may also use <code>%gui = qt</code> in Jupyter or IPython.)</p>
<p>I also happened to have ground truth labels available, so I loaded those up the same way I did the volume, and added it to the visualization:</p>
<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">viewer<span style="color:#666">.</span>add_labels(labels, name<span style="color:#666">=</span><span style="color:#4070a0">&#39;Labels&#39;</span>)
</code></pre></div>







<figure>
    <img
        
            sizes="(min-width: 35em) 1200px, 100vw"
              
            srcset='
            
                   https://mentat.za.net/blog/2019/08/06/portland-microscopy/napari-ct-volume_hu1f49f705645b1d6504d5c2bd42dc12b3_109127_480x0_resize_q75_box.jpg 480w,
            
                   https://mentat.za.net/blog/2019/08/06/portland-microscopy/napari-ct-volume_hu1f49f705645b1d6504d5c2bd42dc12b3_109127_800x0_resize_q75_box.jpg 800w,
            
                   https://mentat.za.net/blog/2019/08/06/portland-microscopy/napari-ct-volume_hu1f49f705645b1d6504d5c2bd42dc12b3_109127_1200x0_resize_q75_box.jpg 1200w,
            
                   
            '

            
            
            src="https://mentat.za.net/blog/2019/08/06/portland-microscopy/napari-ct-volume_hu1f49f705645b1d6504d5c2bd42dc12b3_109127_800x0_resize_q75_box.jpg"
            

        /> 
</figure>

<p>If you&rsquo;d like to play with Napari yourself, I have a <a href="https://gist.github.com/stefanv/7c296c26b0c3624746f4317bed6a3540">3D cell segmentation example available online</a>.</p>
<h2 id="community">Community</h2>
<p>Toward the conclusion of my talk, I emphasized the role of community in building healthy scientific software ecosystems.  In the end, it is <em>all about people</em>.  I briefly highlight two community groups:</p>
<ul>
<li>
<p><a href="https://pangeo.io/">PanGeo</a>, whom I think sets a great example of how to organize field-specific interest around existing open source tools, and building scalable online analysis platforms without reinventing the wheel.</p>
</li>
<li>
<p><a href="https://www.openmicroscopy.org/">OME</a>, the Open Microscopy Environment, who is leading the charge on open data exchange formats for microscopy.  Interestingly, it <a href="https://blog.openmicroscopy.org/community/file-formats/2019/06/25/formats/">looks like</a> <a href="https://zarr.readthedocs.io">Zarr</a>â€”the chunked, compressed array containerâ€”may well be part of the next open standard they recommend.</p>
</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>Thank you to the organizers of M&amp;M 2019 for inviting me to speak; I very much enjoyed our session, and look forward to working with this community on making scientific Python an <em>even better</em> platform for mirocroscopy analysis!</p>


		<script type="text/javascript">
  var disqus_identifier = "http://stefanv.github.com/blog/2019/08/06/portland-microscopy/";
</script>

<div style="border-top: 0.5px solid #e5e5e5; padding-top: 1em;">
  <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "stefanvdwalt" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div>

	</div>

	<div class="pagination">
		<a href="/blog/2019/07/05/intelligent-augmentation/" class="left arrow">&#8592;</a>
		<a href="/blog/2020/04/28/voice-capture-org-tasks-on-android/" class="right arrow">&#8594;</a>

		<a href="#" class="top">Top</a>
	</div>
</main>


        		<footer>
			<span>
			&copy; <time datetime="2020-05-21 10:47:10.705268137 -0700 PDT m=&#43;0.070686430">2020</time> . Made with <a href='https://gohugo.io'>Hugo</a> using the <a href='https://github.com/EmielH/tale-hugo/'>Tale</a> theme.
			</span>
		</footer>

    </body>
</html>
